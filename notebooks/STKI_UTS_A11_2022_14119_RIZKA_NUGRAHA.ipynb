{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proyek UTS: Sistem Temu Kembali Informasi (STKI)\n",
        "## Mini Search Engine (Boolean & Vector Space Model)\n",
        "\n",
        " Proyek ini adalah implementasi dari sistem temu kembali informasi (STKI) mini sebagai pemenuhan Ujian Tengah Semester (UTS) Ganjil 2025/2026. Sistem ini dibangun menggunakan Python, mampu mengindeks 5 dokumen berita, dan mendukung dua model pencarian: **Boolean Retrieval** dan **Vector Space Model (VSM)** dengan perankingan TF-IDF.\n",
        "\n",
        "Aplikasi ini juga di-deploy menggunakan Streamlit Community Cloud dan dapat diakses secara publik.\n",
        "\n",
        "**Tautan Aplikasi Streamlit:** `https://uts-stki-14119.streamlit.app`\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§‘â€ðŸŽ“ Informasi Mahasiswa\n",
        "\n",
        "* **Nama:** `Rizka Nugraha`\n",
        "* **NIM:** `A11.2022.14119`\n",
        "* **Mata Kuliah:** Sistem Temu Kembali Informasi (A11.4703)\n",
        "* **Dosen:** Abu Salam, M.Kom\n",
        "* **Universitas:** Universitas Dian Nuswantoro\n",
        "\n",
        "---\n",
        "\n",
        "Notebook Google Colab ini berfungsi sebagai script eksekusi utama untuk proyek UTS STKI. Notebook ini akan menjalankan pengujian dan evaluasi untuk setiap modul yang diminta dalam soal, yaitu:\n",
        "* **Soal 02:** Document Preprocessing\n",
        "* **Soal 03:** Boolean Retrieval Model\n",
        "* **Soal 04:** Vector Space Model (VSM)\n",
        "* **Soal 05:** Perbandingan Term Weighting & Evaluasi\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aWEkZKiIC174"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_S_4pFBZAwN",
        "outputId": "727f3ab4-2750-498b-b3be-b9450944c1e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/STKI/UTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bwJgDxYXtiB",
        "outputId": "64215fe4-e8bf-4edf-bd80-821c81614fbf"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/STKI/UTS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/STKI/UTS/notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEN5BcFEoomi",
        "outputId": "a6e0240d-4aaf-421f-e0ed-cc3158f7a3d5"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/STKI/UTS/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import library/package**"
      ],
      "metadata": {
        "id": "0qlQvf5VEOl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from pyngrok import ngrok\n",
        "import shutil"
      ],
      "metadata": {
        "id": "sOvfGyn1jetk"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persiapan Data Korpus & Arsitektur\n",
        "\n",
        "Sebelum memulai, kita perlu menyiapkan dua hal:\n",
        "1.  **Menulis Korpus:** Menulis 5 dokumen berita (yang disimpan sebagai string) ke dalam file `../data/raw/beritaX.txt`. Ini adalah sumber data mentah untuk sistem kita.\n",
        "2.  **Membuat Package `src`:** Membuat file `../src/__init__.py` yang kosong. Ini memberi tahu Python bahwa folder `src` adalah sebuah *package*, yang memungkinkan kita mengimpor file `.py` di dalamnya (misal: `from src.preprocess import ...`)."
      ],
      "metadata": {
        "id": "9OPDszixEe1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Menulis 5 file berita ke 'data/raw'... ---\")\n",
        "berita_corpus = {\n",
        "    \"berita1.txt\": \"\"\"Wilayah Kamu Sudah 'Bebas' COVID-19? Cek 34 Kab/Kota Zona Hijau Terbaru\n",
        "Jakarta - Pemerintah rencananya bakal menerapkan Pemberlakuan Pembatasan Kegiatan Masyarakat (PPKM) level 3 terhitung 24 Desember 2021 hingga 2 Januari 2021. Namun, Kementerian Kesehatan RI memastikan kebijakan PPKM level 3 ini masih dalam tahap kajian.\n",
        "Menurut Direktur Pencegahan dan Pengendalian Penyakit Menular Langsung (P2PML) Kemenkes RI dr Siti Nadia Tarmizi, PPKM level 3 bakal diterapkan jika kasus COVID-19 naik signifikan. Hal ini umumnya dipicu dengan peningkatan mobilitas dan pelonggaran protokol kesehatan.\n",
        "https://health.detik.com/berita-detikhealth/d-5816690/wilayah-kamu-sudah-bebas-covid-19-cek-34-kabkota-zona-hijau-terbaru\"\"\",\n",
        "\n",
        "    \"berita2.txt\": \"\"\"Vaksin COVID-19 Bakal Rutin Setiap Tahun? Tergantung, Ini Penjelasannya\n",
        "Jakarta - Pemberian booster atau dosis ketiga vaksin COVID-19 di Indonesia direncanakan bakal berlangsung Januari 2022. Lantas adakah kemungkinan vaksinasi COVID-19 bakal harus dilakukan setiap tahun seperti vaksinasi influenza?\n",
        "Ketua Satgas COVID-19 Ikatan Dokter Indonesia (IDI) Prof Zubairi Djoerban menjelaskan hingga kini belum ada kepastian terkait hal tersebut. Menurutnya masih ada kemungkinan vaksin COVID-19 harus diberikan setiap tahun, ada juga kemungkinan cukup booster diberikan sekali kemudian vaksinasi COVID-19 tidak diperlukan lagi.\n",
        "https://health.detik.com/berita-detikhealth/d-5816582/vaksin-covid-19-bakal-rutin-setiap-tahun-tergantung-ini-penjelasannya\"\"\",\n",
        "\n",
        "    \"berita3.txt\": \"\"\"RI Mulai Suntikkan Booster di 2022, Masihkah Ampuh Lawan Varian Delta Cs?\n",
        "Jakarta - Pakar mengakui vaksin-vaksin yang sudah digunakan untuk dosis 1-2 memang mengalami penurunan efektivitas terhadap varian baru Corona seperti varian Delta. Mengingat booster atau dosis ketiga vaksin COVID-19 di Indonesia disebut bakal dimulai awal 2022, apakah jenis vaksin yang digunakan bakal mengikuti strain virus terbaru?\n",
        "Menjawab pertanyaan tersebut, Ketua Satgas COVID-19 Ikatan Dokter Indonesia (IDI) Prof Zubairi Djoerban kembali menyinggung riset yang sudah berlangsung terkait efektivitas vaksin COVID-19 dosis 1 dan 2. Ia menyebut berdasarkan riset sejauh ini, efektivitas vaksin COVID-19 Pfizer dan Moderna terbukti menurun dalam melawan varian Delta.\n",
        "https://health.detik.com/berita-detikhealth/d-5816534/ri-mulai-suntikkan-booster-di-2022-masihkah-ampuh-lawan-varian-delta-cs\"\"\",\n",
        "\n",
        "    \"berita4.txt\": \"\"\"Alert! Kasus Varian Delta COVID-19 di DKI Meningkat\n",
        "Jakarta - Data terbaru dari Balitbangkes Kemenkes RI per 13 November, menunjukkan adanya penambahan varian Delta. Penambahan tersebut terjadi di Jawa Barat ada 165 kasus, DKI Jakarta 90 kasus, dan Sulawesi Utara 86 kasus.\n",
        "Dalam satu bulan terakhir, Balitbangkes menyebutkan DKI Jakarta mengalami peningkatan kasus varian Delta yang signifikan. Sementara, pada varian baru seperti varian Alpha, varian Delta, hingga Beta terbanyak di Indonesia berasal dari DKI Jakarta, dengan total 1.327 kasus .\n",
        "https://health.detik.com/berita-detikhealth/d-5812940/alert-kasus-varian-delta-covid-19-di-dki-meningkat\"\"\",\n",
        "\n",
        "    \"berita5.txt\": \"\"\"Corona di AS Mendadak Naik Lagi Usai Serangan Delta Sempat Mereda\n",
        "Jakarta - Kasus COVID-19 kembali naik di sejumlah wilayah Amerika Serikat (AS). Padahal diketahui, COVID-19 sempat tercatat stabil pasca serangan varian Delta musim panas ini. Ada apa?\n",
        "Hal tersebut disampaikan oleh kepala penasihat medis Gedung Putih Dr. Anthony Fauci, Senin (15/11/2021). Diketahui, kasus nasional turun 57 persen minggu lalu dari puncak gelombang varian Delta pada musim panas. Namun jumlah pasien COVID-19 di area Barat Tengah dan Timur laut kini naik mendadak.\n",
        "https://health.detik.com/berita-detikhealth/d-5813949/corona-di-as-mendadak-naik-lagi-usai-serangan-delta-sempat-mereda\"\"\"\n",
        "}\n",
        "\n",
        "for filename, content in berita_corpus.items():\n",
        "    with open(os.path.join(\"../data/raw\", filename), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "print(f\"{len(berita_corpus)} file berita berhasil ditulis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFdT_B2ypVDe",
        "outputId": "38759ea4-d2db-43f3-e893-3d74044235fc"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Menulis 5 file berita ke 'data/raw'... ---\n",
            "5 file berita berhasil ditulis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path ke file __init__.py di dalam folder src\n",
        "init_file_path = \"../src/__init__.py\"\n",
        "\n",
        "# Cek jika file belum ada, lalu buat\n",
        "if not os.path.exists(init_file_path):\n",
        "    with open(init_file_path, \"w\") as f:\n",
        "        pass # Buat file kosong\n",
        "    print(f\"File '{init_file_path}' berhasil dibuat.\")\n",
        "    print(\"Folder 'src' sekarang sudah menjadi package Python.\")\n",
        "else:\n",
        "    print(f\"File '{init_file_path}' sudah ada. Tidak perlu dibuat ulang.\")\n",
        "\n",
        "print(\"\\nSilakan coba jalankan ulang sel yang menjalankan aplikasi Streamlit Anda.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e43cb7yKdrE1",
        "outputId": "4b1857db-b0b5-4534-9989-d81475e1419e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File '../src/__init__.py' sudah ada. Tidak perlu dibuat ulang.\n",
            "\n",
            "Silakan coba jalankan ulang sel yang menjalankan aplikasi Streamlit Anda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dependensi NLTK\n",
        "\n",
        "Sel-sel berikutnya mengunduh data yang diperlukan oleh library NLTK:\n",
        "* `punkt`: Diperlukan untuk *tokenisasi* (memecah teks menjadi kata).\n",
        "* `stopwords`: Berisi daftar kata umum Bahasa Indonesia (seperti 'dan', 'di', 'yang') untuk dihapus.\n",
        "* `punkt_tab`: Data tambahan untuk tokenisasi."
      ],
      "metadata": {
        "id": "ijBZIizZEplk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tcR9pIZhl6S",
        "outputId": "0f54eb16-2f41-45b7-bc19-70598c1446a2"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVGa7wMihCQf",
        "outputId": "311e04dd-7319-47cf-9466-03d3bbb6ae34"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reCOgaGihsW-",
        "outputId": "34b63c25-1ac2-443d-e028-60d31b032c8c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eksekusi Soal 02: Document Preprocessing\n",
        "\n",
        "Sel ini menjalankan implementasi **Soal 02**.\n",
        "\n",
        "Prosesnya adalah sebagai berikut:\n",
        "1.  Mengimpor fungsi `preprocess` dari `../src/preprocess.py`.\n",
        "2.  Membaca setiap file dari `../data/raw/`.\n",
        "3.  Menjalankan pipeline preprocessing (case-folding, tokenisasi, stopword removal, stemming).\n",
        "4.  Menyimpan hasilnya ke `../data/processed/`.\n",
        "\n",
        "Sebagai bukti, sel ini akan mencetak perbandingan **\"BEFORE\"** (teks mentah) dan **\"AFTER\"** (teks yang sudah diproses) untuk dua dokumen pertama."
      ],
      "metadata": {
        "id": "FUj4KH2pE7B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"--- Menjalankan Soal 02: Document Preprocessing... ---\")\n",
        "import sys\n",
        "import os # Import os untuk path handling\n",
        "\n",
        "# Tambahkan path saat ini (yaitu folder 'UTS') ke sys.path\n",
        "# Ini agar Python bisa menemukan folder 'src'\n",
        "sys.path.append(os.path.abspath('../'))\n",
        "\n",
        "# --- PATH DIPERBAIKI ---\n",
        "# Karena Anda sudah di dalam 'UTS', 'UTS/' dihapus dari awal path\n",
        "raw_dir = \"../data/raw\"\n",
        "processed_dir = \"../data/processed\"\n",
        "# ---------------------\n",
        "\n",
        "# Pastikan folder 'src' ada\n",
        "if not os.path.exists('../src'):\n",
        "     print(\"ERROR: Folder 'src' tidak ditemukan. Pastikan Anda berada di folder 'UTS'.\")\n",
        "else:\n",
        "    from src.preprocess import preprocess\n",
        "\n",
        "    # Ambil 2 sampel dokumen untuk before/after\n",
        "    #\n",
        "    sample_files = sorted(os.listdir(raw_dir))[:2]\n",
        "    print(\"\\n--- Menampilkan Before/After untuk 2 Sampel Dokumen ---\")\n",
        "\n",
        "    processed_log = []\n",
        "\n",
        "    for doc_id in sorted(os.listdir(raw_dir)):\n",
        "        if not doc_id.endswith('.txt'): continue\n",
        "\n",
        "        with open(os.path.join(raw_dir, doc_id), 'r', encoding='utf-8') as f_in:\n",
        "            raw_content = f_in.read()\n",
        "\n",
        "        processed_content = preprocess(raw_content)\n",
        "\n",
        "        # Simpan keluaran akhir ke data/processed/*.txt\n",
        "        #\n",
        "        with open(os.path.join(processed_dir, doc_id), 'w', encoding='utf-8') as f_out:\n",
        "            f_out.write(processed_content)\n",
        "\n",
        "        log_entry = f\"Dokumen '{doc_id}': Selesai diproses.\"\n",
        "        processed_log.append(log_entry)\n",
        "\n",
        "        # Tampilkan 2 sampel\n",
        "        if doc_id in sample_files:\n",
        "            print(f\"\\n[DOKUMEN: {doc_id}]\")\n",
        "            print(\"--- BEFORE ---\")\n",
        "            print(raw_content[:150] + \"...\")\n",
        "            print(\"\\n--- AFTER ---\")\n",
        "            print(processed_content[:150] + \"...\")\n",
        "\n",
        "    print(\"\\n--- Log Ringkas Proses ---\")\n",
        "    # (log ringkas)\n",
        "    for log in processed_log:\n",
        "        print(log)\n",
        "    print(\"\\nPreprocessing selesai. Hasil disimpan di 'data/processed/'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3PSwVyPe3HH",
        "outputId": "a481cfa8-a16b-4d6f-db00-6f7b6664f496"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Menjalankan Soal 02: Document Preprocessing... ---\n",
            "\n",
            "--- Menampilkan Before/After untuk 2 Sampel Dokumen ---\n",
            "\n",
            "[DOKUMEN: berita1.txt]\n",
            "--- BEFORE ---\n",
            "Wilayah Kamu Sudah 'Bebas' COVID-19? Cek 34 Kab/Kota Zona Hijau Terbaru\n",
            "Jakarta - Pemerintah rencananya bakal menerapkan Pemberlakuan Pembatasan Kegia...\n",
            "\n",
            "--- AFTER ---\n",
            "wilayah bebas covid cek kabkota zona hijau baru jakarta perintah rencana terap laku batas giat masyarakat ppkm level hitung desember januari menteri s...\n",
            "\n",
            "--- Log Ringkas Proses ---\n",
            "Dokumen 'berita1.txt': Selesai diproses.\n",
            "Dokumen 'berita2.txt': Selesai diproses.\n",
            "Dokumen 'berita3.txt': Selesai diproses.\n",
            "Dokumen 'berita4.txt': Selesai diproses.\n",
            "Dokumen 'berita5.txt': Selesai diproses.\n",
            "\n",
            "Preprocessing selesai. Hasil disimpan di 'data/processed/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ../data/raw/berita1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obEglg5NqZSn",
        "outputId": "c8ef9a4f-ac20-4ca6-ee08-dbc5ec3bb057"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wilayah Kamu Sudah 'Bebas' COVID-19? Cek 34 Kab/Kota Zona Hijau Terbaru\n",
            "Jakarta - Pemerintah rencananya bakal menerapkan Pemberlakuan Pembatasan Kegiatan Masyarakat (PPKM) level 3 terhitung 24 Desember 2021 hingga 2 Januari 2021. Namun, Kementerian Kesehatan RI memastikan kebijakan PPKM level 3 ini masih dalam tahap kajian.\n",
            "Menurut Direktur Pencegahan dan Pengendalian Penyakit Menular Langsung (P2PML) Kemenkes RI dr Siti Nadia Tarmizi, PPKM level 3 bakal diterapkan jika kasus COVID-19 naik signifikan. Hal ini umumnya dipicu dengan peningkatan mobilitas dan pelonggaran protokol kesehatan.\n",
            "https://health.detik.com/berita-detikhealth/d-5816690/wilayah-kamu-sudah-bebas-covid-19-cek-34-kabkota-zona-hijau-terbaru"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ../data/processed/berita1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDoBfqX7qeCA",
        "outputId": "46fd35d6-ca7e-452d-edc9-f7bc83648448"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wilayah bebas covid cek kabkota zona hijau baru jakarta perintah rencana terap laku batas giat masyarakat ppkm level hitung desember januari menteri sehat ri bijak ppkm level tahap kaji direktur cegah kendali sakit tular langsung ppml kemenkes ri dr siti nadia tarmizi ppkm level terap covid signifikan picu tingkat mobilitas longgar protokol sehat"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eksekusi Soal 03: Boolean Retrieval Model\n",
        "\n",
        "Sel ini menjalankan implementasi **Soal 03**.\n",
        "\n",
        "Prosesnya adalah:\n",
        "1.  Mengimpor kelas `BooleanRetrieval` dari `../src/boolean_ir.py`.\n",
        "2.  Kelas ini secara otomatis membuat **Inverted Index** dari file di `../data/processed/`.\n",
        "3.  Menjalankan 3 kueri uji untuk operator `AND`, `OR`, dan `NOT`.\n",
        "4.  Menjalankan evaluasi wajib (Soal 03) terhadap *gold standard* manual untuk menghitung **Precision, Recall, dan F1-Score**."
      ],
      "metadata": {
        "id": "S8E1EcyqFKQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Menjalankan Soal 03: Boolean Retrieval Model... ---\")\n",
        "#\n",
        "from src.boolean_ir import BooleanRetrieval\n",
        "from src.eval import calculate_precision_recall_f1\n",
        "\n",
        "processed_dir = \"../data/processed\"\n",
        "bool_model = BooleanRetrieval(processed_dir)\n",
        "\n",
        "# Uji dengan >= 3 query\n",
        "#\n",
        "queries_to_test = [\n",
        "    \"vaksin AND delta\",\n",
        "    \"ppkm OR jakarta\",\n",
        "    \"kasus NOT amerika\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- Pengujian Query Boolean ---\")\n",
        "query_results_bool = {}\n",
        "for q in queries_to_test:\n",
        "    docs, explain = bool_model.process_query(q)\n",
        "    query_results_bool[q] = docs\n",
        "    print(f\"\\nQuery: '{q}'\")\n",
        "    print(f\"Explain: {explain}\")\n",
        "    print(f\"Hasil: {docs}\")\n",
        "\n",
        "# Uji Wajib (mini truth set)\n",
        "#\n",
        "print(\"\\n--- Evaluasi Wajib Boolean (Precision/Recall) ---\")\n",
        "# Buat gold set (ground truth) manual.\n",
        "# ANDA BISA UBAH INI SESUAI ANALISIS ANDA\n",
        "gold_standard_bool = {\n",
        "    \"vaksin AND delta\": {\"berita3.txt\"},\n",
        "    \"ppkm OR jakarta\": {\"berita1.txt\", \"berita4.txt\"},\n",
        "    \"kasus NOT amerika\": {\"berita1.txt\", \"berita2.txt\", \"berita3.txt\", \"berita4.txt\"}\n",
        "}\n",
        "print(f\"Gold Standard (Asumsi): {gold_standard_bool}\")\n",
        "\n",
        "eval_results = []\n",
        "for query, relevant_docs in gold_standard_bool.items():\n",
        "    retrieved_docs = query_results_bool.get(query, [])\n",
        "    p, r, f1 = calculate_precision_recall_f1(retrieved_docs, relevant_docs)\n",
        "    eval_results.append({\n",
        "        \"Query\": query,\n",
        "        \"Retrieved\": len(retrieved_docs),\n",
        "        \"Relevant\": len(relevant_docs),\n",
        "        \"Precision\": p,\n",
        "        \"Recall\": r,\n",
        "        \"F1-Score\": f1\n",
        "    })\n",
        "\n",
        "df_eval_bool = pd.DataFrame(eval_results)\n",
        "print(\"\\nHasil Evaluasi Boolean:\")\n",
        "print(df_eval_bool.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TOosX30ilsD",
        "outputId": "4cfa3df6-fb01-4041-a0e9-2c7aad15cb9c"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Menjalankan Soal 03: Boolean Retrieval Model... ---\n",
            "\n",
            "--- Pengujian Query Boolean ---\n",
            "\n",
            "Query: 'vaksin AND delta'\n",
            "Explain: vaksin (2 dok) AND delta -> 1 dok\n",
            "Hasil: ['berita3.txt']\n",
            "\n",
            "Query: 'ppkm OR jakarta'\n",
            "Explain: ppkm (1 dok) OR jakarta -> 5 dok\n",
            "Hasil: ['berita1.txt', 'berita2.txt', 'berita3.txt', 'berita4.txt', 'berita5.txt']\n",
            "\n",
            "Query: 'kasus NOT amerika'\n",
            "Explain: NOT amerika (4 dok)\n",
            "Hasil: ['berita1.txt', 'berita2.txt', 'berita3.txt', 'berita4.txt']\n",
            "\n",
            "--- Evaluasi Wajib Boolean (Precision/Recall) ---\n",
            "Gold Standard (Asumsi): {'vaksin AND delta': {'berita3.txt'}, 'ppkm OR jakarta': {'berita1.txt', 'berita4.txt'}, 'kasus NOT amerika': {'berita1.txt', 'berita2.txt', 'berita3.txt', 'berita4.txt'}}\n",
            "\n",
            "Hasil Evaluasi Boolean:\n",
            "               Query  Retrieved  Relevant  Precision  Recall  F1-Score\n",
            "0   vaksin AND delta          1         1        1.0     1.0  1.000000\n",
            "1    ppkm OR jakarta          5         2        0.4     1.0  0.571429\n",
            "2  kasus NOT amerika          4         4        1.0     1.0  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Eksekusi Soal 04: Vector Space Model (VSM) & Ranking\n",
        "\n",
        "Sel ini menjalankan implementasi **Soal 04**.\n",
        "\n",
        "Prosesnya adalah:\n",
        "1.  Mengimpor kelas `VectorSpaceModel` dari `../src/vsm_ir.py`.\n",
        "2.  Kelas ini secara otomatis:\n",
        "    * Memuat data mentah dari `../data/raw/`.\n",
        "    * Melakukan preprocessing.\n",
        "    * Membangun **Matriks TF-IDF** (sepotong matriks ditampilkan sebagai bukti).\n",
        "3.  Menjalankan kueri uji (\"varian delta di jakarta\") dan menampilkan hasil **Top-3** yang diurutkan berdasarkan skor **Cosine Similarity**.\n",
        "4. Menjalankan evaluasi wajib (Soal 04) terhadap *gold standard* untuk menghitung **Precision@k** dan **MAP@k (Mean Average Precision)**."
      ],
      "metadata": {
        "id": "nkNktZpuFQtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Menjalankan Soal 04: Vector Space Model & Ranking... ---\")\n",
        "#\n",
        "from src.vsm_ir import VectorSpaceModel\n",
        "from src.eval import precision_at_k, mean_average_precision\n",
        "\n",
        "raw_dir = \"../data/raw\"\n",
        "vsm_model = VectorSpaceModel(raw_dir)\n",
        "\n",
        "# Tampilkan sebagian matriks TF-IDF\n",
        "print(\"\\n--- Menampilkan 5 Term Pertama dari Matriks TF-IDF ---\")\n",
        "df_tfidf = vsm_model.get_tfidf_matrix()\n",
        "print(df_tfidf.iloc[:, :5].to_string())\n",
        "\n",
        "# Uji query\n",
        "print(\"\\n--- Pengujian Query VSM (Top-3) ---\")\n",
        "# (ambil top-k, k=3)\n",
        "query_vsm = \"varian delta di jakarta\"\n",
        "k_vsm = 3\n",
        "vsm_search_results = vsm_model.search(query_vsm, k=k_vsm)\n",
        "\n",
        "print(f\"Query: '{query_vsm}'\")\n",
        "print(f\"Top-{k_vsm} Hasil:\")\n",
        "for res in vsm_search_results:\n",
        "    print(f\"  - [{res['doc_id']}] Score: {res['score']:.4f} | Snippet: {res['snippet']}\")\n",
        "\n",
        "# Uji Wajib: bandingkan dengan gold set\n",
        "#\n",
        "print(\"\\n--- Evaluasi Wajib VSM (P@k & MAP@k) ---\")\n",
        "# Kita pakai query yang sama dengan boolean untuk perbandingan\n",
        "gold_standard_vsm = {\n",
        "    \"vaksin AND delta\": {\"berita2.txt\", \"berita3.txt\"}, # VSM mungkin menangkap 'vaksin' di berita2\n",
        "    \"ppkm OR jakarta\": {\"berita1.txt\", \"berita4.txt\"},\n",
        "    \"kasus NOT amerika\": {\"berita1.txt\", \"berita4.txt\"} # VSM sulit menangani 'NOT'\n",
        "}\n",
        "\n",
        "# Dapatkan hasil VSM untuk setiap query di gold standard\n",
        "query_results_vsm = {}\n",
        "for query in gold_standard_vsm.keys():\n",
        "    query_results_vsm[query] = vsm_model.search(query, k=5) # Ambil K=5\n",
        "\n",
        "# Hitung P@k (P@3) dan MAP@k (MAP@5)\n",
        "#\n",
        "eval_vsm_results = []\n",
        "map_k = 5\n",
        "p_k = 3\n",
        "\n",
        "for query, relevant_docs in gold_standard_vsm.items():\n",
        "    retrieved_docs_data = query_results_vsm.get(query, [])\n",
        "    retrieved_doc_ids = [r['doc_id'] for r in retrieved_docs_data]\n",
        "\n",
        "    p_at_k = precision_at_k(retrieved_doc_ids, relevant_docs, k=p_k)\n",
        "    eval_vsm_results.append({\n",
        "        \"Query\": query,\n",
        "        f\"P@{p_k}\": p_at_k\n",
        "    })\n",
        "\n",
        "map_score = mean_average_precision(query_results_vsm, gold_standard_vsm, k=map_k)\n",
        "\n",
        "print(f\"Gold Standard (Asumsi): {gold_standard_vsm}\")\n",
        "df_eval_vsm = pd.DataFrame(eval_vsm_results)\n",
        "print(f\"\\nHasil Evaluasi VSM (Precision@{p_k}):\")\n",
        "print(df_eval_vsm.to_string())\n",
        "print(f\"\\nSKOR KESELURUHAN: MAP@{map_k} = {map_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B7j3wnoj-IN",
        "outputId": "5bb28fd0-c74f-4e21-9d92-509e73cc349b"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Menjalankan Soal 04: Vector Space Model & Ranking... ---\n",
            "\n",
            "--- Menampilkan 5 Term Pertama dari Matriks TF-IDF ---\n",
            "                  ada       aku     alami     alert     alpha\n",
            "berita1.txt  0.000000  0.000000  0.000000  0.000000  0.000000\n",
            "berita2.txt  0.148874  0.000000  0.000000  0.000000  0.000000\n",
            "berita3.txt  0.000000  0.111765  0.090171  0.000000  0.000000\n",
            "berita4.txt  0.000000  0.000000  0.098029  0.121504  0.121504\n",
            "berita5.txt  0.000000  0.000000  0.000000  0.000000  0.000000\n",
            "\n",
            "--- Pengujian Query VSM (Top-3) ---\n",
            "Query: 'varian delta di jakarta'\n",
            "Top-3 Hasil:\n",
            "  - [berita4.txt] Score: 0.6181 | Snippet: Alert! Kasus Varian Delta COVID-19 di DKI Meningkat Jakarta - Data terbaru dari Balitbangkes Kemenkes RI per 13 November...\n",
            "  - [berita3.txt] Score: 0.3549 | Snippet: RI Mulai Suntikkan Booster di 2022, Masihkah Ampuh Lawan Varian Delta Cs? Jakarta - Pakar mengakui vaksin-vaksin yang su...\n",
            "  - [berita5.txt] Score: 0.3159 | Snippet: Corona di AS Mendadak Naik Lagi Usai Serangan Delta Sempat Mereda Jakarta - Kasus COVID-19 kembali naik di sejumlah wila...\n",
            "\n",
            "--- Evaluasi Wajib VSM (P@k & MAP@k) ---\n",
            "Gold Standard (Asumsi): {'vaksin AND delta': {'berita2.txt', 'berita3.txt'}, 'ppkm OR jakarta': {'berita1.txt', 'berita4.txt'}, 'kasus NOT amerika': {'berita1.txt', 'berita4.txt'}}\n",
            "\n",
            "Hasil Evaluasi VSM (Precision@3):\n",
            "               Query       P@3\n",
            "0   vaksin AND delta  0.666667\n",
            "1    ppkm OR jakarta  0.666667\n",
            "2  kasus NOT amerika  0.000000\n",
            "\n",
            "SKOR KESELURUHAN: MAP@5 = 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eksekusi Soal 05: Perbandingan Term Weighting\n",
        "\n",
        "Sel ini menjalankan implementasi inti dari **Soal 05 (Langkah 1 & 4)**, yaitu membandingkan dua skema *term weighting*.\n",
        "\n",
        "Prosesnya adalah:\n",
        "1.  **Memuat Ulang Modul:** `importlib.reload` digunakan untuk memastikan notebook ini menggunakan versi terbaru `vsm_ir.py` (yang telah diupdate untuk menerima opsi `sublinear_tf`).\n",
        "2.  **Inisialisasi Model:** Membuat dua instance `VectorSpaceModel`:\n",
        "    * `vsm_model_default`: Menggunakan TF-IDF standar (`sublinear_tf=False`).\n",
        "    * `vsm_model_sublinear`: Menggunakan TF-IDF Sublinear (`sublinear_tf=True`).\n",
        "3.  **Evaluasi:** Menjalankan *gold standard* yang sama pada kedua model.\n",
        "4.  **Laporan:** Mencetak tabel perbandingan skor **MAP@5** dari kedua skema, diikuti dengan analisis singkat."
      ],
      "metadata": {
        "id": "ghckQE1CFg3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- [Eksekusi Soal 05]: Perbandingan Term Weighting (Langkah 1 & 4) ---\")\n",
        "\n",
        "import importlib\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "\n",
        "# Muat ulang modul yang baru saja kita ubah\n",
        "import src.vsm_ir\n",
        "import src.eval\n",
        "importlib.reload(src.vsm_ir)\n",
        "importlib.reload(src.eval)\n",
        "\n",
        "from src.vsm_ir import VectorSpaceModel\n",
        "from src.eval import mean_average_precision\n",
        "\n",
        "raw_dir = \"../data/raw\"\n",
        "\n",
        "# 1. Inisialisasi model dengan 2 skema berbeda\n",
        "print(\"Membuat model VSM (Default TF-IDF)...\")\n",
        "vsm_model_default = VectorSpaceModel(raw_dir, sublinear_tf=False)\n",
        "\n",
        "print(\"Membuat model VSM (Sublinear TF-IDF)...\")\n",
        "vsm_model_sublinear = VectorSpaceModel(raw_dir, sublinear_tf=True)\n",
        "\n",
        "# 2. Siapkan Gold Standard (sama seperti Soal 04)\n",
        "#\n",
        "gold_standard_vsm = {\n",
        "    \"vaksin AND delta\": {\"berita2.txt\", \"berita3.txt\"},\n",
        "    \"ppkm OR jakarta\": {\"berita1.txt\", \"berita4.txt\"},\n",
        "    \"kasus NOT amerika\": {\"berita1.txt\", \"berita4.txt\"}\n",
        "}\n",
        "map_k = 5\n",
        "\n",
        "# 3. Evaluasi Skema 1 (Default)\n",
        "query_results_default = {}\n",
        "for query in gold_standard_vsm.keys():\n",
        "    query_results_default[query] = vsm_model_default.search(query, k=map_k)\n",
        "map_default = mean_average_precision(query_results_default, gold_standard_vsm, k=map_k)\n",
        "\n",
        "# 4. Evaluasi Skema 2 (Sublinear)\n",
        "query_results_sublinear = {}\n",
        "for query in gold_standard_vsm.keys():\n",
        "    query_results_sublinear[query] = vsm_model_sublinear.search(query, k=map_k)\n",
        "map_sublinear = mean_average_precision(query_results_sublinear, gold_standard_vsm, k=map_k)\n",
        "\n",
        "# 5. Laporkan pengaruhnya terhadap metrik\n",
        "#\n",
        "print(\"\\n--- Laporan Perbandingan Metrik (MAP@5) ---\")\n",
        "# (Tabel perbandingan, bukan grafik)\n",
        "comparison_data = {\n",
        "    \"Skema Weighting\": [\"Default TF-IDF\", \"Sublinear TF-IDF\"],\n",
        "    f\"MAP@{map_k}\": [map_default, map_sublinear]\n",
        "}\n",
        "df_comparison = pd.DataFrame(comparison_data).set_index(\"Skema Weighting\")\n",
        "print(df_comparison.to_string())\n",
        "\n",
        "print(\"\\n--- Analisis Singkat (Wajib untuk Laporan) ---\")\n",
        "print(f\"Penggunaan Sublinear TF-IDF (MAP={map_sublinear:.4f}) menghasilkan skor yang \"\n",
        "      f\"{'lebih tinggi' if map_sublinear > map_default else 'lebih rendah atau sama'}\"\n",
        "      f\" dibandingkan Default TF-IDF (MAP={map_default:.4f}) pada gold set ini.\")\n",
        "print(\"Sublinear TF mengganti 'tf' mentah dengan '1 + log(tf)',\")\n",
        "print(\"yang berguna untuk menangani perbedaan frekuensi kata yang ekstrem.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAEgkMnomTcs",
        "outputId": "f2d2fcde-2f6b-4be8-8115-6d81ea70c52a"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- [Eksekusi Soal 05]: Perbandingan Term Weighting (Langkah 1 & 4) ---\n",
            "Membuat model VSM (Default TF-IDF)...\n",
            "Membuat model VSM (Sublinear TF-IDF)...\n",
            "\n",
            "--- Laporan Perbandingan Metrik (MAP@5) ---\n",
            "                     MAP@5\n",
            "Skema Weighting           \n",
            "Default TF-IDF    0.666667\n",
            "Sublinear TF-IDF  0.666667\n",
            "\n",
            "--- Analisis Singkat (Wajib untuk Laporan) ---\n",
            "Penggunaan Sublinear TF-IDF (MAP=0.6667) menghasilkan skor yang lebih rendah atau sama dibandingkan Default TF-IDF (MAP=0.6667) pada gold set ini.\n",
            "Sublinear TF mengganti 'tf' mentah dengan '1 + log(tf)',\n",
            "yang berguna untuk menangani perbedaan frekuensi kata yang ekstrem.\n"
          ]
        }
      ]
    }
  ]
}